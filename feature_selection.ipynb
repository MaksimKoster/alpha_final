{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "import pickle\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_rf_feature_selection(X, y, threshold=\"mean\", random_state=SEED):\n",
    "    clf = LGBMClassifier(\n",
    "        boosting_type='rf',\n",
    "        n_estimators=146,  # Number of trees\n",
    "        max_depth=16,  # Maximum depth of trees\n",
    "        min_child_samples=211,  # Minimum number of samples per leaf\n",
    "        min_child_weight=649,  # Minimum sum of weights of all observations required in a child\n",
    "        n_jobs=16,\n",
    "        random_state=random_state,\n",
    "        bagging_freq=1,  # Frequency for bagging\n",
    "        bagging_fraction=0.9,  # Fraction of data to be used for bagging\n",
    "        feature_fraction=0.9,  # Fraction of features to be used for training\n",
    "        subsample=None,\n",
    "        colsample_bytree=None,\n",
    "        subsample_freq=None,\n",
    "        verbose=-1,\n",
    "        device='gpu',\n",
    "        gpu_device_id=0\n",
    "    )\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    selector = SelectFromModel(clf, threshold=threshold, prefit=True)\n",
    "    mask = selector.get_support()\n",
    "\n",
    "    importances = clf.feature_importances_\n",
    "    feature_ranking = np.argsort(importances)[::-1]\n",
    "    print(\"Top 10 Feature Importances:\")\n",
    "    for i in feature_ranking[:10]:\n",
    "        print(f\"Feature {i}: {importances[i]:.4f}\")\n",
    "\n",
    "    return mask, clf\n",
    "\n",
    "\n",
    "def process_dataset(name, train_path, test_path, output_dir, random_state=SEED):\n",
    "    print(f\"Processing dataset: {name}\")\n",
    "    \n",
    "    df_train = pd.read_parquet(train_path).sort_values(\"id\")\n",
    "    df_test = pd.read_parquet(test_path).sort_values(\"id\")\n",
    "\n",
    "    feature_cols = [col for col in df_train.columns if col not in [\"id\", \"smpl\", \"target\"]]\n",
    "    \n",
    "    X_train = df_train[feature_cols].to_numpy()\n",
    "    y_train = df_train[\"target\"].to_numpy()\n",
    "\n",
    "    feature_mask, model = lgbm_rf_feature_selection(X_train, y_train, threshold=\"mean\", random_state=random_state)\n",
    "    \n",
    "    X_train_selected = X_train[:, feature_mask]\n",
    "    selected_features = [feature_cols[i] for i, m in enumerate(feature_mask) if m]\n",
    "\n",
    "    df_train_selected = df_train[[\"id\", \"smpl\", \"target\"] + selected_features]\n",
    "    \n",
    "    X_test = df_test[feature_cols].to_numpy()\n",
    "    X_test_selected = X_test[:, feature_mask]\n",
    "    df_test_selected = df_test[[\"id\", \"smpl\"] + selected_features]\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    train_output = os.path.join(output_dir, f\"{name}_train_selected.parquet\")\n",
    "    test_output = os.path.join(output_dir, f\"{name}_test_selected.parquet\")\n",
    "    df_train_selected.to_parquet(train_output)\n",
    "    df_test_selected.to_parquet(test_output)\n",
    "    \n",
    "    # tscv = TimeSeriesSplit(n_splits=5)\n",
    "    # cv_splits = []\n",
    "    # for fold, (tr_idx, val_idx) in enumerate(tscv.split(X_train_selected, y_train), 1):\n",
    "    #     cv_splits.append({\n",
    "    #         \"fold\": fold,\n",
    "    #         \"train_index\": tr_idx,\n",
    "    #         \"validation_index\": val_idx\n",
    "    #     })\n",
    "    #     print(f\"Fold {fold}: Train indices {tr_idx[0]} to {tr_idx[-1]}, Validation indices {val_idx[0]} to {val_idx[-1]}\")\n",
    "    \n",
    "    # cv_splits_path = os.path.join(output_dir, f\"{name}_cv_splits.pkl\")\n",
    "    # with open(cv_splits_path, \"wb\") as f:\n",
    "    #     pickle.dump(cv_splits, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    # Save feature mask\n",
    "    # feature_mask_path = os.path.join(output_dir, f\"{name}_feature_mask.npy\")\n",
    "    # np.save(feature_mask_path, feature_mask)\n",
    "    \n",
    "    print(f\"Selected {X_train_selected.shape[1]} out of {X_train.shape[1]} features.\")\n",
    "    print(f\"Train saved to: {train_output}\")\n",
    "    print(f\"Test saved to: {test_output}\")\n",
    "    # print(f\"CV splits saved to: {cv_splits_path}\")\n",
    "    # print(f\"Feature mask saved to: {feature_mask_path}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = \"/home/rbparchiev/alpha_hackathon/alpha_hack/data\"\n",
    "DATA_DIR = \"/home/rbparchiev/alpha_hackathon/alpha_step_2/data/Alfa Hack. Данные для финалистов/data/\"\n",
    "data_paths = {\n",
    "    \"fl_credit_card_tendency\": DATA_DIR+\"fl_credit_card_tendency/fl_credit_card_tendency_train.parquet\",\n",
    "    \"invest_prop_4\": DATA_DIR+\"invest_prop_4/train\",\n",
    "    \"outflow_12\": DATA_DIR+\"outflow_12/outflow_12_train.parquet\",\n",
    "    \"pd_fl\": DATA_DIR+\"pd_fl/pd_fl_train.parquet\",\n",
    "    \"pd_ul_9\": DATA_DIR+\"pd_ul_9/pd_ul_9_train.parquet\",\n",
    "    \"ul_leasing_outflow\": DATA_DIR+\"ul_leasing_outflow/ul_leasing_outflow_train.parquet\",\n",
    "}\n",
    "\n",
    "data_paths_test = {\n",
    "    \"fl_credit_card_tendency\": DATA_DIR+\"fl_credit_card_tendency/fl_credit_card_tendency_test.parquet\",\n",
    "    \"invest_prop_4\": DATA_DIR+\"invest_prop_4/invest_prop_4_test.parquet\",\n",
    "    \"outflow_12\": DATA_DIR+\"outflow_12/outflow_12_test.parquet\",\n",
    "    \"pd_fl\": DATA_DIR+\"pd_fl/pd_fl_test.parquet\",\n",
    "    \"pd_ul_9\": DATA_DIR+\"pd_ul_9/pd_ul_9_test.parquet\",\n",
    "    \"ul_leasing_outflow\": DATA_DIR+\"ul_leasing_outflow/ul_leasing_outflow_test.parquet\",\n",
    "}\n",
    "\n",
    "output_dir = \"./data_fs_rf/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: fl_credit_card_tendency\n",
      "Top 10 Feature Importances:\n",
      "Feature 150: 601.0000\n",
      "Feature 63: 393.0000\n",
      "Feature 342: 350.0000\n",
      "Feature 233: 323.0000\n",
      "Feature 34: 298.0000\n",
      "Feature 153: 286.0000\n",
      "Feature 49: 282.0000\n",
      "Feature 420: 258.0000\n",
      "Feature 172: 148.0000\n",
      "Feature 156: 147.0000\n",
      "Selected 33 out of 500 features.\n",
      "Train saved to: ./data_fs_rf/fl_credit_card_tendency_train_selected.parquet\n",
      "Test saved to: ./data_fs_rf/fl_credit_card_tendency_test_selected.parquet\n",
      "--------------------------------------------------\n",
      "Processing dataset: invest_prop_4\n",
      "Top 10 Feature Importances:\n",
      "Feature 46: 491.0000\n",
      "Feature 79: 416.0000\n",
      "Feature 382: 343.0000\n",
      "Feature 10: 319.0000\n",
      "Feature 365: 293.0000\n",
      "Feature 47: 260.0000\n",
      "Feature 352: 212.0000\n",
      "Feature 30: 154.0000\n",
      "Feature 102: 145.0000\n",
      "Feature 243: 140.0000\n",
      "Selected 40 out of 500 features.\n",
      "Train saved to: ./data_fs_rf/invest_prop_4_train_selected.parquet\n",
      "Test saved to: ./data_fs_rf/invest_prop_4_test_selected.parquet\n",
      "--------------------------------------------------\n",
      "Processing dataset: outflow_12\n",
      "Top 10 Feature Importances:\n",
      "Feature 167: 653.0000\n",
      "Feature 86: 374.0000\n",
      "Feature 141: 189.0000\n",
      "Feature 123: 165.0000\n",
      "Feature 5: 150.0000\n",
      "Feature 146: 143.0000\n",
      "Feature 71: 137.0000\n",
      "Feature 126: 134.0000\n",
      "Feature 77: 127.0000\n",
      "Feature 70: 95.0000\n",
      "Selected 32 out of 186 features.\n",
      "Train saved to: ./data_fs_rf/outflow_12_train_selected.parquet\n",
      "Test saved to: ./data_fs_rf/outflow_12_test_selected.parquet\n",
      "--------------------------------------------------\n",
      "Processing dataset: pd_fl\n",
      "Top 10 Feature Importances:\n",
      "Feature 420: 443.0000\n",
      "Feature 233: 288.0000\n",
      "Feature 99: 274.0000\n",
      "Feature 153: 262.0000\n",
      "Feature 382: 234.0000\n",
      "Feature 167: 178.0000\n",
      "Feature 17: 151.0000\n",
      "Feature 492: 149.0000\n",
      "Feature 44: 141.0000\n",
      "Feature 49: 141.0000\n",
      "Selected 45 out of 500 features.\n",
      "Train saved to: ./data_fs_rf/pd_fl_train_selected.parquet\n",
      "Test saved to: ./data_fs_rf/pd_fl_test_selected.parquet\n",
      "--------------------------------------------------\n",
      "Processing dataset: pd_ul_9\n",
      "Top 10 Feature Importances:\n",
      "Feature 0: 0.0000\n",
      "Feature 417: 0.0000\n",
      "Feature 39: 0.0000\n",
      "Feature 38: 0.0000\n",
      "Feature 37: 0.0000\n",
      "Feature 36: 0.0000\n",
      "Feature 35: 0.0000\n",
      "Feature 34: 0.0000\n",
      "Feature 33: 0.0000\n",
      "Feature 32: 0.0000\n",
      "Selected 418 out of 418 features.\n",
      "Train saved to: ./data_fs_rf/pd_ul_9_train_selected.parquet\n",
      "Test saved to: ./data_fs_rf/pd_ul_9_test_selected.parquet\n",
      "--------------------------------------------------\n",
      "Processing dataset: ul_leasing_outflow\n",
      "Top 10 Feature Importances:\n",
      "Feature 46: 281.0000\n",
      "Feature 420: 266.0000\n",
      "Feature 99: 247.0000\n",
      "Feature 365: 167.0000\n",
      "Feature 385: 136.0000\n",
      "Feature 57: 136.0000\n",
      "Feature 418: 135.0000\n",
      "Feature 91: 129.0000\n",
      "Feature 24: 109.0000\n",
      "Feature 243: 98.0000\n",
      "Selected 62 out of 500 features.\n",
      "Train saved to: ./data_fs_rf/ul_leasing_outflow_train_selected.parquet\n",
      "Test saved to: ./data_fs_rf/ul_leasing_outflow_test_selected.parquet\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, train_path in data_paths.items():\n",
    "    test_path = data_paths_test[name]\n",
    "    process_dataset(name, train_path, test_path, output_dir, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
