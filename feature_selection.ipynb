{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "import pickle\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_rf_feature_selection(X, y, threshold=\"mean\", random_state=SEED):\n",
    "    clf = LGBMClassifier(\n",
    "        boosting_type='rf',\n",
    "        n_estimators=100,\n",
    "        n_jobs=16,\n",
    "        random_state=random_state,\n",
    "        bagging_freq=1,\n",
    "        bagging_fraction=0.9,\n",
    "        feature_fraction=0.9,\n",
    "        # subsample=0.9,\n",
    "        subsample=None,\n",
    "        colsample_bytree=None,\n",
    "        subsample_freq=None,\n",
    "        verbose=-1\n",
    "    )\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    selector = SelectFromModel(clf, threshold=threshold, prefit=True)\n",
    "    mask = selector.get_support()\n",
    "\n",
    "    importances = clf.feature_importances_\n",
    "    feature_ranking = np.argsort(importances)[::-1]\n",
    "    print(\"Top 10 Feature Importances:\")\n",
    "    for i in feature_ranking[:10]:\n",
    "        print(f\"Feature {i}: {importances[i]:.4f}\")\n",
    "\n",
    "    return mask, clf\n",
    "\n",
    "\n",
    "def process_dataset(name, train_path, test_path, output_dir, random_state=SEED):\n",
    "    print(f\"Processing dataset: {name}\")\n",
    "    \n",
    "    df_train = pl.read_parquet(train_path).sort(\"id\")\n",
    "    df_test = pl.read_parquet(test_path).sort(\"id\")\n",
    "\n",
    "    feature_cols = [col for col in df_train.columns if col not in [\"id\", \"smpl\", \"target\"]]\n",
    "    \n",
    "    X_train = df_train.select(feature_cols).to_numpy()\n",
    "    y_train = df_train[\"target\"].to_numpy()\n",
    "\n",
    "    feature_mask, model = lgbm_rf_feature_selection(X_train, y_train, threshold=\"mean\", random_state=random_state)\n",
    "    \n",
    "    X_train_selected = X_train[:, feature_mask]\n",
    "    selected_features = [feature_cols[i] for i, m in enumerate(feature_mask) if m]\n",
    "\n",
    "    df_train_selected = df_train.select([\"id\", \"smpl\", \"target\"] + selected_features)\n",
    "    \n",
    "    X_test = df_test.select(feature_cols).to_numpy()\n",
    "    X_test_selected = X_test[:, feature_mask]\n",
    "    df_test_selected = df_test.select([\"id\", \"smpl\"] + selected_features)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    train_output = os.path.join(output_dir, f\"{name}_train_selected.parquet\")\n",
    "    test_output = os.path.join(output_dir, f\"{name}_test_selected.parquet\")\n",
    "    df_train_selected.write_parquet(train_output)\n",
    "    df_test_selected.write_parquet(test_output)\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    cv_splits = []\n",
    "    for fold, (tr_idx, val_idx) in enumerate(tscv.split(X_train_selected, y_train), 1):\n",
    "        cv_splits.append({\n",
    "            \"fold\": fold,\n",
    "            \"train_index\": tr_idx,\n",
    "            \"validation_index\": val_idx\n",
    "        })\n",
    "        print(f\"Fold {fold}: Train indices {tr_idx[0]} to {tr_idx[-1]}, Validation indices {val_idx[0]} to {val_idx[-1]}\")\n",
    "    \n",
    "    cv_splits_path = os.path.join(output_dir, f\"{name}_cv_splits.pkl\")\n",
    "    with open(cv_splits_path, \"wb\") as f:\n",
    "        pickle.dump(cv_splits, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    # Save feature mask\n",
    "    feature_mask_path = os.path.join(output_dir, f\"{name}_feature_mask.npy\")\n",
    "    np.save(feature_mask_path, feature_mask)\n",
    "    \n",
    "    print(f\"Selected {X_train_selected.shape[1]} out of {X_train.shape[1]} features.\")\n",
    "    print(f\"Train saved to: {train_output}\")\n",
    "    print(f\"Test saved to: {test_output}\")\n",
    "    print(f\"CV splits saved to: {cv_splits_path}\")\n",
    "    print(f\"Feature mask saved to: {feature_mask_path}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/rbparchiev/alpha_hackathon/alpha_step_2/data/Alfa Hack. Данные для финалистов/data/\"\n",
    "data_paths = {\n",
    "    \"fl_credit_card_tendency\": DATA_DIR+\"fl_credit_card_tendency/fl_credit_card_tendency_train.parquet\",\n",
    "    \"invest_prop_4\": DATA_DIR+\"invest_prop_4/train\",\n",
    "    \"outflow_12\": DATA_DIR+\"outflow_12/outflow_12_train.parquet\",\n",
    "    \"pd_fl\": DATA_DIR+\"pd_fl/pd_fl_train.parquet\",\n",
    "    \"pd_ul_9\": DATA_DIR+\"pd_ul_9/pd_ul_9_train.parquet\",\n",
    "    \"ul_leasing_outflow\": DATA_DIR+\"ul_leasing_outflow/ul_leasing_outflow_train.parquet\",\n",
    "}\n",
    "\n",
    "data_paths_test = {\n",
    "    \"fl_credit_card_tendency\": DATA_DIR+\"fl_credit_card_tendency/fl_credit_card_tendency_test.parquet\",\n",
    "    \"invest_prop_4\": DATA_DIR+\"invest_prop_4/invest_prop_4_test.parquet\",\n",
    "    \"outflow_12\": DATA_DIR+\"outflow_12/outflow_12_test.parquet\",\n",
    "    \"pd_fl\": DATA_DIR+\"pd_fl/pd_fl_test.parquet\",\n",
    "    \"pd_ul_9\": DATA_DIR+\"pd_ul_9/pd_ul_9_test.parquet\",\n",
    "    \"ul_leasing_outflow\": DATA_DIR+\"ul_leasing_outflow/ul_leasing_outflow_test.parquet\",\n",
    "}\n",
    "\n",
    "output_dir = \"/home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: fl_credit_card_tendency\n",
      "Top 10 Feature Importances:\n",
      "Feature 150: 349.0000\n",
      "Feature 63: 283.0000\n",
      "Feature 172: 275.0000\n",
      "Feature 233: 223.0000\n",
      "Feature 34: 208.0000\n",
      "Feature 153: 196.0000\n",
      "Feature 49: 190.0000\n",
      "Feature 420: 172.0000\n",
      "Feature 342: 133.0000\n",
      "Feature 156: 96.0000\n",
      "Fold 1: Train indices 0 to 147548, Validation indices 147549 to 295095\n",
      "Fold 2: Train indices 0 to 295095, Validation indices 295096 to 442642\n",
      "Fold 3: Train indices 0 to 442642, Validation indices 442643 to 590189\n",
      "Fold 4: Train indices 0 to 590189, Validation indices 590190 to 737736\n",
      "Fold 5: Train indices 0 to 737736, Validation indices 737737 to 885283\n",
      "Selected 36 out of 500 features.\n",
      "Train saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/fl_credit_card_tendency_train_selected.parquet\n",
      "Test saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/fl_credit_card_tendency_test_selected.parquet\n",
      "CV splits saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/fl_credit_card_tendency_cv_splits.pkl\n",
      "Feature mask saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/fl_credit_card_tendency_feature_mask.npy\n",
      "--------------------------------------------------\n",
      "Processing dataset: invest_prop_4\n",
      "Top 10 Feature Importances:\n",
      "Feature 79: 285.0000\n",
      "Feature 365: 221.0000\n",
      "Feature 156: 195.0000\n",
      "Feature 46: 183.0000\n",
      "Feature 252: 167.0000\n",
      "Feature 167: 160.0000\n",
      "Feature 382: 147.0000\n",
      "Feature 10: 128.0000\n",
      "Feature 150: 110.0000\n",
      "Feature 420: 99.0000\n",
      "Fold 1: Train indices 0 to 449045, Validation indices 449046 to 898091\n",
      "Fold 2: Train indices 0 to 898091, Validation indices 898092 to 1347137\n",
      "Fold 3: Train indices 0 to 1347137, Validation indices 1347138 to 1796183\n",
      "Fold 4: Train indices 0 to 1796183, Validation indices 1796184 to 2245229\n",
      "Fold 5: Train indices 0 to 2245229, Validation indices 2245230 to 2694275\n",
      "Selected 42 out of 500 features.\n",
      "Train saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/invest_prop_4_train_selected.parquet\n",
      "Test saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/invest_prop_4_test_selected.parquet\n",
      "CV splits saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/invest_prop_4_cv_splits.pkl\n",
      "Feature mask saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/invest_prop_4_feature_mask.npy\n",
      "--------------------------------------------------\n",
      "Processing dataset: outflow_12\n",
      "Top 10 Feature Importances:\n",
      "Feature 86: 316.0000\n",
      "Feature 123: 255.0000\n",
      "Feature 167: 252.0000\n",
      "Feature 15: 218.0000\n",
      "Feature 126: 214.0000\n",
      "Feature 71: 187.0000\n",
      "Feature 77: 153.0000\n",
      "Feature 125: 147.0000\n",
      "Feature 133: 111.0000\n",
      "Feature 25: 102.0000\n",
      "Fold 1: Train indices 0 to 68868, Validation indices 68869 to 137733\n",
      "Fold 2: Train indices 0 to 137733, Validation indices 137734 to 206598\n",
      "Fold 3: Train indices 0 to 206598, Validation indices 206599 to 275463\n",
      "Fold 4: Train indices 0 to 275463, Validation indices 275464 to 344328\n",
      "Fold 5: Train indices 0 to 344328, Validation indices 344329 to 413193\n",
      "Selected 27 out of 186 features.\n",
      "Train saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/outflow_12_train_selected.parquet\n",
      "Test saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/outflow_12_test_selected.parquet\n",
      "CV splits saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/outflow_12_cv_splits.pkl\n",
      "Feature mask saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/outflow_12_feature_mask.npy\n",
      "--------------------------------------------------\n",
      "Processing dataset: pd_fl\n",
      "Top 10 Feature Importances:\n",
      "Feature 156: 417.0000\n",
      "Feature 420: 260.0000\n",
      "Feature 153: 178.0000\n",
      "Feature 233: 167.0000\n",
      "Feature 382: 161.0000\n",
      "Feature 99: 135.0000\n",
      "Feature 492: 108.0000\n",
      "Feature 167: 100.0000\n",
      "Feature 345: 99.0000\n",
      "Feature 17: 99.0000\n",
      "Fold 1: Train indices 0 to 151433, Validation indices 151434 to 302863\n",
      "Fold 2: Train indices 0 to 302863, Validation indices 302864 to 454293\n",
      "Fold 3: Train indices 0 to 454293, Validation indices 454294 to 605723\n",
      "Fold 4: Train indices 0 to 605723, Validation indices 605724 to 757153\n",
      "Fold 5: Train indices 0 to 757153, Validation indices 757154 to 908583\n",
      "Selected 41 out of 500 features.\n",
      "Train saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/pd_fl_train_selected.parquet\n",
      "Test saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/pd_fl_test_selected.parquet\n",
      "CV splits saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/pd_fl_cv_splits.pkl\n",
      "Feature mask saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/pd_fl_feature_mask.npy\n",
      "--------------------------------------------------\n",
      "Processing dataset: pd_ul_9\n",
      "Top 10 Feature Importances:\n",
      "Feature 50: 204.0000\n",
      "Feature 323: 109.0000\n",
      "Feature 277: 91.0000\n",
      "Feature 10: 89.0000\n",
      "Feature 255: 83.0000\n",
      "Feature 268: 74.0000\n",
      "Feature 385: 65.0000\n",
      "Feature 235: 45.0000\n",
      "Feature 271: 42.0000\n",
      "Feature 181: 32.0000\n",
      "Fold 1: Train indices 0 to 6455, Validation indices 6456 to 12910\n",
      "Fold 2: Train indices 0 to 12910, Validation indices 12911 to 19365\n",
      "Fold 3: Train indices 0 to 19365, Validation indices 19366 to 25820\n",
      "Fold 4: Train indices 0 to 25820, Validation indices 25821 to 32275\n",
      "Fold 5: Train indices 0 to 32275, Validation indices 32276 to 38730\n",
      "Selected 105 out of 418 features.\n",
      "Train saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/pd_ul_9_train_selected.parquet\n",
      "Test saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/pd_ul_9_test_selected.parquet\n",
      "CV splits saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/pd_ul_9_cv_splits.pkl\n",
      "Feature mask saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/pd_ul_9_feature_mask.npy\n",
      "--------------------------------------------------\n",
      "Processing dataset: ul_leasing_outflow\n",
      "Top 10 Feature Importances:\n",
      "Feature 233: 304.0000\n",
      "Feature 47: 259.0000\n",
      "Feature 24: 230.0000\n",
      "Feature 420: 194.0000\n",
      "Feature 57: 171.0000\n",
      "Feature 99: 159.0000\n",
      "Feature 352: 150.0000\n",
      "Feature 102: 106.0000\n",
      "Feature 250: 104.0000\n",
      "Feature 120: 98.0000\n",
      "Fold 1: Train indices 0 to 38431, Validation indices 38432 to 76861\n",
      "Fold 2: Train indices 0 to 76861, Validation indices 76862 to 115291\n",
      "Fold 3: Train indices 0 to 115291, Validation indices 115292 to 153721\n",
      "Fold 4: Train indices 0 to 153721, Validation indices 153722 to 192151\n",
      "Fold 5: Train indices 0 to 192151, Validation indices 192152 to 230581\n",
      "Selected 47 out of 500 features.\n",
      "Train saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/ul_leasing_outflow_train_selected.parquet\n",
      "Test saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/ul_leasing_outflow_test_selected.parquet\n",
      "CV splits saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/ul_leasing_outflow_cv_splits.pkl\n",
      "Feature mask saved to: /home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/ul_leasing_outflow_feature_mask.npy\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, train_path in data_paths.items():\n",
    "    test_path = data_paths_test[name]\n",
    "    process_dataset(name, train_path, test_path, output_dir, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha_final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
