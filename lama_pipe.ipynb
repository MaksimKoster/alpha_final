{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/sb-ai-lab/LightAutoML.git\n",
    "# ! pip download -d lightautoml_packages LightAutoML\n",
    "# ! pip install --no-index --find-links=lightautoml_packages LightAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.set_start_method('spawn', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rbparchiev/miniconda3/envs/alpha_final/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/rbparchiev/miniconda3/envs/alpha_final/lib/python3.10/site-packages/lightautoml/ml_algo/dl_model.py:42: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "/home/rbparchiev/miniconda3/envs/alpha_final/lib/python3.10/site-packages/lightautoml/text/embed.py:22: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "/home/rbparchiev/miniconda3/envs/alpha_final/lib/python3.10/site-packages/lightautoml/text/dl_transformers.py:25: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, precision_score, recall_score\n",
    "from lightautoml.automl.presets.tabular_presets import TabularUtilizedAutoML\n",
    "from lightautoml.tasks import Task\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/rbparchiev/alpha_hackathon/alpha_step_2/data/data_fs_rf/\"\n",
    "OUTPUT_DIR = os.path.join(DATA_DIR, \"lightautoml_results\")\n",
    "SUBMISSION_DIR = os.path.join(OUTPUT_DIR, \"submissions\")\n",
    "os.makedirs(SUBMISSION_DIR, exist_ok=True)\n",
    "\n",
    "datasets = [\n",
    "    \"fl_credit_card_tendency\",\n",
    "    \"invest_prop_4\",\n",
    "    \"outflow_12\",\n",
    "    \"pd_fl\",\n",
    "    \"pd_ul_9\",\n",
    "    \"ul_leasing_outflow\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_TIME = int(3600 * 4) - 600\n",
    "TIMEOUT_PER_DATASET = TOTAL_TIME // len(datasets)\n",
    "N_THREADS = 16\n",
    "N_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name):\n",
    "    train_path = os.path.join(DATA_DIR, f\"{name}_train_selected.parquet\")\n",
    "    test_path = os.path.join(DATA_DIR, f\"{name}_test_selected.parquet\")\n",
    "    cv_splits_path = os.path.join(DATA_DIR, f\"{name}_cv_splits.pkl\")\n",
    "\n",
    "    df_train = pl.read_parquet(train_path)\n",
    "    df_test = pl.read_parquet(test_path)\n",
    "\n",
    "    with open(cv_splits_path, \"rb\") as f:\n",
    "        cv_splits = pickle.load(f)\n",
    "\n",
    "    return df_train, df_test, cv_splits\n",
    "\n",
    "def train_and_evaluate_lightautoml(df_train, cv_splits, dataset_name, timeout):\n",
    "    train_pd = df_train.to_pandas()\n",
    "\n",
    "    task = Task('binary')\n",
    "    roles = {\n",
    "        'target': 'target',\n",
    "        'drop': ['id', 'smpl']\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    fold_timeout = timeout // len(cv_splits) if len(cv_splits) > 0 else timeout\n",
    "    for fold_dict in cv_splits:\n",
    "        tr_idx, val_idx = fold_dict[\"train_index\"], fold_dict[\"validation_index\"]\n",
    "        X_train_fold = train_pd.iloc[tr_idx].reset_index(drop=True)\n",
    "        X_val_fold = train_pd.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        automl = TabularUtilizedAutoML(\n",
    "            task=task,\n",
    "            timeout=fold_timeout,\n",
    "            cpu_limit=N_THREADS,\n",
    "            reader_params={'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': SEED}\n",
    "        )\n",
    "        oof_preds_fold = automl.fit_predict(X_train_fold, roles=roles, verbose=1)\n",
    "        val_pred = automl.predict(X_val_fold)\n",
    "        val_pred_proba = val_pred.data[:, 0]\n",
    "\n",
    "        score = roc_auc_score(X_val_fold['target'].values, val_pred_proba)\n",
    "        scores.append(score)\n",
    "\n",
    "        del automl\n",
    "        gc.collect()\n",
    "\n",
    "    if scores:\n",
    "        print(f\"LightAutoML CV scores for {dataset_name}: {scores}, mean: {np.mean(scores):.4f}\")\n",
    "    else:\n",
    "        print(f\"No CV splits provided for {dataset_name}, skipping CV evaluation.\")\n",
    "\n",
    "    automl_full = TabularUtilizedAutoML(\n",
    "        task=task,\n",
    "        timeout=timeout,\n",
    "        cpu_limit=N_THREADS,\n",
    "        reader_params={'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': SEED}\n",
    "    )\n",
    "    oof_preds_full = automl_full.fit_predict(train_pd, roles=roles, verbose=1)\n",
    "    full_score = roc_auc_score(train_pd['target'].values, oof_preds_full.data[:, 0])\n",
    "    print(f\"Full training OOF score for {dataset_name}: {full_score:.4f}\")\n",
    "\n",
    "    return automl_full\n",
    "\n",
    "def make_submission(df_test, model, dataset_name):\n",
    "    test_pd = df_test.to_pandas()\n",
    "\n",
    "    test_pred = model.predict(test_pd)\n",
    "    test_pred_proba = test_pred.data[:, 0]\n",
    "\n",
    "    submission = pl.DataFrame({\n",
    "        \"id\": test_pd[\"id\"],\n",
    "        \"prediction\": test_pred_proba\n",
    "    })\n",
    "\n",
    "    submission_path = os.path.join(SUBMISSION_DIR, f\"{dataset_name}_lightautoml_submission.csv\")\n",
    "    submission.write_csv(submission_path)\n",
    "    print(f\"Submission saved for {dataset_name}: {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: fl_credit_card_tendency, allocated timeout: 2300 seconds\n",
      "[02:10:45] Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n",
      "[02:10:45] - time: 460.00 seconds\n",
      "[02:10:45] - CPU: 16 cores\n",
      "[02:10:45] - memory: 16 GB\n",
      "\n",
      "[02:10:45] \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
      "\n",
      "[02:10:45] ==================================================\n",
      "[02:10:45] Start 0 automl preset configuration:\n",
      "[02:10:45] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n",
      "[02:10:45] Stdout logging level is INFO.\n",
      "[02:10:45] Task: binary\n",
      "\n",
      "[02:10:45] Start automl preset with listed constraints:\n",
      "[02:10:45] - time: 460.00 seconds\n",
      "[02:10:45] - CPU: 16 cores\n",
      "[02:10:45] - memory: 16 GB\n",
      "\n",
      "[02:10:45] \u001b[1mTrain data shape: (147549, 39)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rbparchiev/miniconda3/envs/alpha_final/lib/python3.10/site-packages/joblib/externals/loky/backend/fork_exec.py:37: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "If you really know what your doing, you can silence this warning with the warning module\n",
      "or by setting POLARS_ALLOW_FORKING_THREAD=1.\n",
      "\n",
      "  pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:53] Layer \u001b[1m1\u001b[0m train process start. Time left 451.26 secs\n",
      "[02:11:04] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[02:11:27] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7857183450784795\u001b[0m\n",
      "[02:11:27] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[02:11:27] Time left 417.77 secs\n",
      "\n",
      "[02:11:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[02:11:58] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8035609379402759\u001b[0m\n",
      "[02:11:58] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[02:11:58] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 25.24 secs\n",
      "[02:11:58] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[02:12:26] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[02:12:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[02:12:42] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8033243711268784\u001b[0m\n",
      "[02:12:42] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[02:12:42] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[02:13:44] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8041223383773487\u001b[0m\n",
      "[02:13:44] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[02:13:44] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 21.78 secs\n",
      "[02:14:15] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[02:14:15] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[02:16:09] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8042850500666575\u001b[0m\n",
      "[02:16:09] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[02:16:09] Time left 135.27 secs\n",
      "\n",
      "[02:16:09] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[02:16:09] Blending: optimization starts with equal weights and score \u001b[1m0.8042390558304492\u001b[0m\n",
      "[02:16:11] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8052399275022912\u001b[0m, weights = \u001b[1m[0.         0.27077597 0.20611079 0.24636908 0.27674422]\u001b[0m\n",
      "[02:16:12] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8052401460976479\u001b[0m, weights = \u001b[1m[0.         0.2723934  0.20683429 0.23895727 0.28181505]\u001b[0m\n",
      "[02:16:13] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8052402657848396\u001b[0m, weights = \u001b[1m[0.         0.27584606 0.2076662  0.23353915 0.28294855]\u001b[0m\n",
      "[02:16:14] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8052403297842405\u001b[0m, weights = \u001b[1m[0.         0.27549616 0.20867126 0.23324291 0.28258964]\u001b[0m\n",
      "[02:16:15] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.805240339296417\u001b[0m, weights = \u001b[1m[0.         0.27548587 0.20870075 0.2332342  0.28257912]\u001b[0m\n",
      "[02:16:15] \u001b[1mAutoml preset training completed in 330.05 seconds\u001b[0m\n",
      "\n",
      "[02:16:15] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.27549 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.20870 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.23323 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.28258 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[02:16:15] ==================================================\n",
      "[02:16:23] Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n",
      "[02:16:23] - time: 460.00 seconds\n",
      "[02:16:23] - CPU: 16 cores\n",
      "[02:16:23] - memory: 16 GB\n",
      "\n",
      "[02:16:23] \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
      "\n",
      "[02:16:23] ==================================================\n",
      "[02:16:23] Start 0 automl preset configuration:\n",
      "[02:16:23] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n",
      "[02:16:23] Stdout logging level is INFO.\n",
      "[02:16:23] Task: binary\n",
      "\n",
      "[02:16:23] Start automl preset with listed constraints:\n",
      "[02:16:23] - time: 460.00 seconds\n",
      "[02:16:23] - CPU: 16 cores\n",
      "[02:16:23] - memory: 16 GB\n",
      "\n",
      "[02:16:23] \u001b[1mTrain data shape: (295096, 39)\u001b[0m\n",
      "\n",
      "[02:16:31] Layer \u001b[1m1\u001b[0m train process start. Time left 451.89 secs\n",
      "[02:16:50] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[02:17:17] Time limit exceeded after calculating fold 2\n",
      "\n",
      "[02:17:17] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7955400009439736\u001b[0m\n",
      "[02:17:17] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[02:17:17] Time left 405.70 secs\n",
      "\n",
      "[02:17:36] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[02:18:09] Time limit exceeded after calculating fold 3\n",
      "\n",
      "[02:18:09] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8106074660307351\u001b[0m\n",
      "[02:18:09] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[02:18:09] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "[02:18:17] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[02:18:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[02:18:54] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8102126330588393\u001b[0m\n",
      "[02:18:54] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[02:18:54] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[02:20:07] Time limit exceeded after calculating fold 1\n",
      "\n",
      "[02:20:07] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8105239913123545\u001b[0m\n",
      "[02:20:07] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[02:20:07] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "[02:20:43] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[02:20:43] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[02:23:19] Time limit exceeded after calculating fold 2\n",
      "\n",
      "[02:23:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8112172863823724\u001b[0m\n",
      "[02:23:19] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[02:23:19] Time left 43.90 secs\n",
      "\n",
      "[02:23:19] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "[02:23:19] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[02:23:19] Blending: optimization starts with equal weights and score \u001b[1m0.8111377368999142\u001b[0m\n",
      "[02:23:21] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8118096834537221\u001b[0m, weights = \u001b[1m[0.         0.27999568 0.12930334 0.33305192 0.25764912]\u001b[0m\n",
      "[02:23:24] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8118112176783785\u001b[0m, weights = \u001b[1m[0.         0.26808193 0.14686449 0.30605668 0.27899686]\u001b[0m\n",
      "[02:23:27] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8118113355355668\u001b[0m, weights = \u001b[1m[0.         0.26968795 0.14578134 0.30536473 0.27916598]\u001b[0m\n",
      "[02:23:29] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8118113355355668\u001b[0m, weights = \u001b[1m[0.         0.26968795 0.14578134 0.30536473 0.27916598]\u001b[0m\n",
      "[02:23:29] Blending: no score update. Terminated\n",
      "\n",
      "[02:23:29] \u001b[1mAutoml preset training completed in 426.56 seconds\u001b[0m\n",
      "\n",
      "[02:23:29] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.26969 * (4 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.14578 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.30536 * (2 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.27917 * (3 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[02:23:29] ==================================================\n",
      "[02:23:37] Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n",
      "[02:23:37] - time: 460.00 seconds\n",
      "[02:23:37] - CPU: 16 cores\n",
      "[02:23:37] - memory: 16 GB\n",
      "\n",
      "[02:23:37] \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
      "\n",
      "[02:23:37] ==================================================\n",
      "[02:23:37] Start 0 automl preset configuration:\n",
      "[02:23:37] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n",
      "[02:23:37] Stdout logging level is INFO.\n",
      "[02:23:37] Task: binary\n",
      "\n",
      "[02:23:37] Start automl preset with listed constraints:\n",
      "[02:23:37] - time: 460.00 seconds\n",
      "[02:23:37] - CPU: 16 cores\n",
      "[02:23:37] - memory: 16 GB\n",
      "\n",
      "[02:23:37] \u001b[1mTrain data shape: (442643, 39)\u001b[0m\n",
      "\n",
      "[02:23:45] Layer \u001b[1m1\u001b[0m train process start. Time left 451.62 secs\n",
      "[02:24:15] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for i, dataset_name in enumerate(datasets):\n",
    "    elapsed = time.time() - start_time\n",
    "    remaining = TOTAL_TIME - elapsed\n",
    "    if remaining <= 0:\n",
    "        print(\"No time left to process remaining datasets.\")\n",
    "        break\n",
    "\n",
    "    dataset_timeout = min(TIMEOUT_PER_DATASET, int(remaining))\n",
    "    if dataset_timeout <= 0:\n",
    "        print(f\"No sufficient time left for {dataset_name}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing dataset: {dataset_name}, allocated timeout: {dataset_timeout} seconds\")\n",
    "    df_train, df_test, cv_splits = load_data(dataset_name)\n",
    "    laml_model = train_and_evaluate_lightautoml(df_train, cv_splits, dataset_name, dataset_timeout)\n",
    "    make_submission(df_test, laml_model, dataset_name)\n",
    "\n",
    "    del df_train, df_test, cv_splits, laml_model\n",
    "    gc.collect()\n",
    "\n",
    "print(\"All submissions generated (or as many as time allowed) successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha_final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
